# audio-dataset

Audio Dataset for training CLAP and other models. In this readme, we define the standard and method to store and process
the audio data. Please feel free to propose idea or comments for this documentation. We will iterate several rounds to
have a final version.

## Overview

For audio dataset, our data process pipline is: raw dataset -> processed dataset (audio+json) -> webdataset (set of
`.tar`).

## Raw dataset

The raw dataset refers to the raw form of the dataset as they downloaded (presumably
from [https://deploy.laion.ai](https://deploy.laion.ai)). They might have various file format, and might have metadata,
captions, or labels, stored in different format. We will take the raw dataset and process them to a unified data storage
format.

Please find the list of raw dataset
in: https://docs.google.com/document/d/1Lvbz5A8tXB1s5piBo0JxKTfpgiYLjTLe0qwk6QtPR9w/edit

You may also find the list at the [end](#raw-dataset-list) of this document.
## Processed dataset

The processed dataset contains only audio files and its labels. The audio is saved in `.flac` format with a sample rate
of `48000`. The label of the audio, including captions/class labels/tags/metadata, are stored in a `.json` file with
same filename as the `.flac` file. The file is renamed in processed dataset, and name format in precessed dataset is in
number id (`1.wav`, `1.json`), to avoid parsing error in subsequent processing caused by file name.

### Key of each type of label and its format

The label of the audio is saved in a `.json` file as a dict. The key of the data labels and its format:

- `text`: The text of the audio which would be used to train the model. The `text` is a list containing strings where
  each entry is one caption/description. This could be caption, description, or made up text description of the audio
  from tags (e.g.: "This is an audio containing A, B, and C.").
- `tag`: The tag of the audio. `tag` is a list containing strings where each entry is one tag. This could be class
  label (e.g., AudioSet) or tag of the audio without having the notion of class label, or metadata of the audio.
- `original_data`: Any form of original data associated with the audio. Can be in arbitary form as long as consistent
  inside dataset. For example, if the original data of the audio is not in the form of tag or text description, you
  could save the original data here.
- (Please add more to here if you come up with more types of label)

### Create conda enviroment

```
conda env create -f environment.yml
```
### Preprocess scripts

In `data_preprocess`folder, you could find the codes and scripts for each raw dataset. If you contribute to process a
new dataset, please add your scripts to `data_preprocess`folder.

You can find the codes to process audio files in `utils/audio_utils`.

An example of preprocess raw dataset can be found in `data_preprocess/preprocess_clotho.py`.

### Split the Dataset

For each raw dataset, we should leave-out part of the dataset as test set. When generating `.flac` and `.json` files,
please also split the dataset. The `.flac` and `.json` files should be generated under the folder of the split name.

For datasets that have a split itself (e.g., Clotho or AudioSet), use the dataset split and name it as
train/valid/test (for only two splits, name train/test). For datasets that have custom splits (e.g., AudioSet), name the
split according to the dataset split. If there is no split of the dataset, please randomly leave-out 10% of the dataset
as test set.

```
preprocessed_dataset_dir
├── Dataset_A
│   ├── train
│   └── test
├── Dataset_B (if have train/test/split)
│   ├── train
│   ├── valid
│   └── test
└── Dataset_C (if have custom split)
│   ├── train
│   ├── custom_split_1
│   └── custom_split_2
```

### Making tar files

The `tardir` function in the `make_tar_utils.py` script creates the tars that includes the audio and text files in the
same folder. One can indicate how much pairs of files should be in the tar. For example, calling
this `make_tar_utils.tardir(file_path='PATH\TO\THE\WHERE\AUDIO_TEXT_PAIRS\LOCATE', tar_name='PATH\TO\THE\OUTPUT\FOLDER\TARFILENAME', n_entry_each=some int number)`
will give you `n_entry_each` pairs of (audio, text) files pairs in each tar files naming like `TARFILENAME0`
, `TARFILENAME1` etc. All the audio `.flac` and text `.json` files in `file_path` will be packed up.

The `load_from_tar` load `(audio, text, name)` tuples from a specific `.tar` file with some choice of audio decoding
parameters. See the documentation of the function in detail. And, of course, we have a different function for
the `dataloader`. This function is just for debugging and reading `tar` files temporarily.

## Webdataset

We use the [webdataset](https://github.com/webdataset/webdataset) as the final format to save the data for better
data-loading performance when training the models. The webdataset packs all the files in processed dataset into several
`.tar` files. Each `.tar` files contain a subset of the processed dataset files. These `.tar` files would be the one
read by dataloader when we train the models.

The standard of webdataset and ways to create the webdataset:
```
python make_tar.py --input /mnt/audio_clip/processed_datasets/audiocaps/ --output /mnt/audio_clip/webdataset_tar/audiocaps/ --dataclass all --num_element 512 --filename name
```
Meaning of this command:
- We are expecting (`.flac`, `.json`) file pairs in `/mnt/audio_clip/processed_datasets/audiocaps/{}/` where {} could be `train`, `test`, `valid` which should be indicate in `dataclass`.

```
......
   ├── 
   preprocessed_dataset_dir
   ├── audiocaps
   │   ├── train
   │   ├── valid
   │   └── test
```

- We will have outputed tar files like `/mnt/audio_clip/webdataset_tar/audiocaps/train/name0.tar`. Each tar includes 512 (`.flac`, `.json`) file pairs.
- We will have outputed `sizes.json` indicating the size of each `tar` file in the folder.
```
......
   ├── 
   webdataset_tar
   ├── audiocaps
   │   ├── train
   |   |     ├── sizes.json
   |   |     ├── name0.tar
   |   |     ├── name1.tar
   |   |     └── ...
   │   ├── valid
   |   |     ├── sizes.json
   |   |     ├── name0.tar
   |   |     ├── name1.tar
   |   |     └── ...
   │   └── test
             └── ...
```

The outputed `sizes.json` will be like
```
{
    "name0.tar": 512,
    "name1.tar": 512,
    ...
}
```

## Directory Structure

Raw dataset: All the raw datasets are stored in [https://deploy.laion.ai](https://deploy.laion.ai).

Preprocessed dataset & webdataset: all the preprocessed dataset & webdataset are stored in (TBD) (TODO: figure out a
place to save). If you contribute to process a new dataset, please move the final webdataset to the above location.

## Contribute

To contribute, please make a branch of yourself and make pull requests to the main branch.

If you contribute to process a new dataset, please add your scripts to `data_preprocess`folder.

If you contribute to process a new dataset, please move the final webdataset to the [TODO: determine location].

## *Raw Dataset List 
| Name                                             | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | URL                                                                      | Text Type                                                                | Status (Location at Laion and AWS S3)                     |
|--------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|-------------------------|
| AudioSet                                         |The AudioSet dataset is a large-scale collection of human-labeled 10-second sound clips drawn from YouTube videos. To collect all our data we worked with human annotators who verified the presence of sounds they heard within YouTube segments. To nominate segments for annotation, we relied on YouTube metadata and content-based search. The sound events in the dataset consist of a subset of the AudioSet ontology. You can learn more about the dataset construction in our ICASSP 2017 paper. Explore the dataset annotations by sound class below. There are 2,084,320 YouTube videos containing 527 labels   | [click here](https://research.google.com/audioset/)                                                    | tag                                                      | [S3](s3://laion-audio/webdataset_tar/audioset/)                                                         |
| BBC sound effects                                |33066 sound effects with text description. Type: mostly environmental sound. Each audio has a natural text description. (need to see check the license)                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | [click here](https://sound-effects.bbcrewind.co.uk/)                                   | 1 text description per audio                                             | [laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaab/)<br> [S3](s3://laion-audio/webdataset_tar/BBCSoundEffects/)|
| AudioCaps                                        |40 000 audio clips of 10 seconds, organized in three splits; a training slipt, a validation slipt, and a testing slipt. Type: environmental sound.                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | [click here](https://audiocaps.github.io/)                                             | 1 text description per audio                                             | [laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaab/)<br> [S3](s3://laion-audio/webdataset_tar/audiocaps/)|
| Audio Caption Hospital Dataset                   |3700 audio clips from "Hospital" scene and around 3600 audio clips from the "Car" scene. Every audio clip is 10 seconds long and is annotated with five captions. Type: environmental sound.                                                                                                                                                                                                                                                                                                                                                                                                                               | [click here](https://zenodo.org/record/4671263#.ygdban-znpy)                           | 5 text description per audio                                             |                                                         |
| Clotho dataset                                   |Clotho consists of 6974 audio samples, and each audio sample has five captions (a total of 34 870 captions). Audio samples are of 15 to 30 s duration and captions are eight to 20 words long. Type: environmental sound.                                                                                                                                                                                                                                                                                                                                                                                                  | [click here](https://zenodo.org/record/4783391#.ygdaa9-znpy)                           | 5 text description per audio                                             |[laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaaa/)<br> [S3](s3://laion-audio/webdataset_tar/Clotho/)|
| Audiostock                                       |Royalty Free Music Library. 436864 audio effects, each with a text description.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | [click here](https://audiostock.net/se)                                                | 1 text description per audio                                             |                                                         |
| ESC-50                                           |2000 environmental audio recordings with 50 classes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | [click here](https://github.com/karolpiczak/esc-50)                                    | tag                                                                      |                                                         |
| UrbanSound8K                                     |8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | [click here](https://urbansounddataset.weebly.com/urbansound8k.html)                   | tag                                                                      |                                                         |
| FMA                                              |917 GiB and 343 days of Creative Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres.                                                                                                                                                                                                                                                                                                                                                                                                                                                      | [click here](https://github.com/mdeff/fma)                                             | tag and free-form text such as biographies (not necessarily descriptive) |                                                         |
| FSD50K                                           |51,197 audio clips of 200 classes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | [click here](https://annotator.freesound.org/fsd/release/fsd50k/)                      | tag                                                                      |                                                         |
| ACAV100M                                         |100M video clips with audio, each 10 sec, with automatic AudioSet, Kinetics400 and Imagenet labels. -> Noisy, but LARGE.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [click here](https://acav100m.azurewebsites.net/explore_classification)                | categories                                                               |                                                         |
| 3                                                |10000+ for 23$ :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | [click here](https://www.freetousesounds.com/product/all-in-one-sound-library-bundle/) | captions tags                                                            | [laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaab/)|
| MACS - Multi-Annotator Captioned Soundscapes     |This is a dataset containing audio captions and corresponding audio tags for a number of 3930 audio files of the TAU Urban Acoustic Scenes 2019 development dataset (airport, public square, and park). The files were annotated using a web-based tool. Each file is annotated by multiple annotators that provided tags and a one-sentence description of the audio content.   The data also includes annotator competence estimated using MACE (Multi-Annotator Competence Estimation).                                                                                                                                 | [click here](https://zenodo.org/record/5114771#.yq4kbnbmlb1)                |                                                                          |                                                         |
| Sonniss Game effects                             |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | no link                                                                  | tags                                                                     |[laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaaa/)<br> [S3](s3://laion-audio/webdataset_tar/sonnis_game_effects/)|
| WeSoundEffects                                   |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | no link                                                                  | tags                                                                     |[laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaaa/) <br> [S3](s3://laion-audio/webdataset_tar/wesoundeffects/)|
| Paramount Motion - Odeon Cinematic Sound Effects |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | no link                                                                  | tags                                                                     |[laion.ai](https://deploy.laion.ai/0fed69941baaabaeccedc2aaaaaaaaaa/)<br> [S3](s3://laion-audio/webdataset_tar/paramount_motion/)|
| Free Sound                                       |https://freesound.org/ Audio with text description (noisy)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | [click here](https://freesound.org/)                                                   | text                                                                     |                                                         |
| Sound Ideas                                      |Sound effects library                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | [click here](https://www.sound-ideas.com/default.aspx)                                 | text                                                                     |                                                         |
| Boom Library                                     |Sound effects library                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | [click here](https://www.boomlibrary.com/)                                             | text                                                                     |                                                         |
| Pitch fork                                       |music review website                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | [click here](https://pitchfork.com/)                                                   | text (long paragraphs)                                                   |                                                         |
| Epidemic Sound                                   |https://www.epidemicsound.com/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | [Click here](https://www.epidemicsound.com/)                                                                     |                                                                          |                                                         |
| Estimation of total Text-audio data              | 33066+40000+3700+6974+436864+10000+3930=0.5M                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | no link                                                                          |                                                                          |                                                         |
| Estimation of total tag-audio data               |2,084,320+2000+8732+51,197+100M~=102M, without ACAV100M it will be ~2.2M                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | no link                                                                         |                                                                          |                                                         |
| People‘s speech                                  | 30k+ hours en-text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[click here](https://mlcommons.org/en/peoples-speech/)                                                |   |   |
| Multilingual spoken words                        | 6k+ hours 1sec audio clips with words of 50+ languages                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |[click here](https://mlcommons.org/en/multilingual-spoken-words/)                                     |   |   |
| AISHELL-2                                        | contains 1000 hours of clean read-speech data from iOS is free for academic usage.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[click here](https://paperswithcode.com/dataset/aishell-2)                                            |   |   |
| surfing ai                                       | 30k+ - proprietary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[click here](http://www.surfing.ai/speech-data/)                                                      |   |   |
| LibriSpeech                                      | a collection of approximately 1,000 hours of audiobooks that are a part of the LibriVox project.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |[click here](https://paperswithcode.com/dataset/librispeech)                                          |   |   |
| Europarl-ST                                      | a Multilingual Speech Translation Corpus, that contains paired audio-text samples for Speech Translation, constructed using the debates carried out in the European Parliament in the period between 2008 and 2012.                                                                                                                                                                                                                                                                                                                                                                                                      |[click here](https://www.mllp.upv.es/europarl-st/)                                                    |   |   |
| CoVoST                                           | a large-scale multilingual ST corpus based on Common Voice, to foster ST research with the largest ever open dataset. Its latest version covers translations from English into 15 languages---Arabic, Catalan, Welsh, German, Estonian, Persian, Indonesian, Japanese, Latvian, Mongolian, Slovenian, Swedish, Tamil, Turkish, Chinese---and from 21 languages into English, including the 15 target languages as well as Spanish, French, Italian, Dutch, Portuguese, Russian. It has total 2,880 hours of speech and is diversified with 78K speakers.                                                                 |[Click here](https://github.com/facebookresearch/covost)                                      |                       |   |
| GigaSpeech                                       | an evolving, multi-domain English speech recognition corpus with 10,000 hours of high quality labeled audio suitable for supervised training, and 40,000 hours of total audio suitable for semi-supervised and unsupervised training.                                                                                                                                                                                                                                                                                                                                                                                    |[Click here](https://github.com/speechcolab/gigaspeech)                                      |                       |   |
| LJSpeech Dataset                                 | This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours.                                                                                                                                                                                                                                                                                                                                     |[Click here](https://keithito.com/lj-speech-dataset/)  <br> Or <br> [download](https://data.keithito.com/data/speech/ljspeech-1.1.tar.bz2)  |                       |   |
| Spotify English-Language Podcast Dataset         | This dataset consists of 100,000 episodes from different podcast shows on Spotify. The dataset is available for research purposes. We are releasing this dataset more widely to facilitate research on podcasts through the lens of speech and audio technology, natural language processing, information retrieval, and linguistics. The dataset contains about 50,000 hours of audio, and over 600 million transcribed words. The episodes span a variety of lengths, topics, styles, and qualities. Only non-commercial research is permitted on this dataset                                                         |[Click here](https://podcastsdataset.byspotify.com/)                                        |                       |   |
| Juno - Music review                              | https://www.juno.co.uk/products/wu-tang-clan-the-charmels-cream/861381-01/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |[Click here](https://www.juno.co.uk/products/wu-tang-clan-the-charmels-cream/861381-01/) |                     |   |
| AudioGrounding dataset                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |no link                                                                         |                       |   |
| Fine-grained Vocal Imitation Set                 | This dataset includes 763 crowd-sourced vocal imitations of 108 sound events.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |[Click here](https://zenodo.org/record/3538534)                                          | audio / sound effects |   |
| VimSketch Dataset                                | VimSketch Dataset combines two publicly available datasets, created by the Interactive Audio Lab for the task of Query by Vocal Imitation (QBV). VimSketch contains 542 reference sounds (including a variety of animal sounds, musical snippets, and environmental noise samples) and 12,543 vocal imitations of those reference sounds with a minimum of 13 and a maximum of 37 vocal imitations per reference.                                                                                                                                                                                                        |[Click here](https://zenodo.org/record/2596911)                                          | audio / sound effects |   |
| OtoMobile Dataset                                | OtoMobile dataset is a collection of recordings of failing car components, created by the Interactive Audio Lab at Northwestern University. OtoMobile consists of 65 recordings of vehicles with failing components, along with annotations.                                                                                                                                                                                                                                                                                                                                                                             |[Click here](https://zenodo.org/record/3382945) <br>(restricted access)                                |                       |   |
| Canadian  French  Emotional (CaFE)  speech  dataset                                | This paper introduces the newly released Canadian French Emotional (CaFE) speech dataset and gives details about its design and content. This dataset contains six different sentences, pronounced by six male and six female actors, in six basic emotions plus one neutral emotion. The six basic emotions are acted in two different intensities. The audio is digitally recorded at high-resolution (192 kHz sampling rate, 24 bits per sample). This new dataset is freely available under a Creative Commons license (CC BY-NC-SA 4.0)                      |[Paper](https://dl.acm.org/doi/10.1145/3204949.3208121) [Download](https://zenodo.org/record/1478765)      | audio / transcription                       |   |

### Music Dataset List
| Name                            | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | URL                                                                                                                                        | Text Type   | Status(location)  |
|---------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------                                                                                                                                                                                                                                                                                                                                                                                                                    |--------------------------------------------------------------------------                                                                  |-------------|-------------------|
|        Free Music Archive       | We introduce the Free Music Archive (FMA), an open and easily accessible dataset suitable for evaluating several tasks in MIR, a field concerned with browsing, searching, and organizing large music collections. The community's growing interest in feature and end-to-end learning is however restrained by the limited availability of large audio datasets. The FMA aims to overcome this hurdle by providing 917 GiB and 343 days of Creative Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres. It provides full-length and high-quality audio, pre-computed features, together with track- and user-level metadata, tags, and free-form text such as biographies. We here describe the dataset and how it was created, propose a train/validation/test split and three subsets, discuss some suitable MIR tasks, and evaluate some baselines for genre recognition. Code, data, and usage examples are available at https://github.com/mdeff/fma. | [Click here](https://academictorrents.com/details/dba20c45d4d6fa6453a4e99d2f8a4817893cfb94)                                                | Music |                         |
|             MusicNet            |                                                                                                                                                                 MusicNet is a collection of 330 freely-licensed classical music recordings, together with over 1 million annotated labels indicating the precise time of each note in every recording, the instrument that plays each note, and the note's position in the metrical structure of the composition. The labels are acquired from musical scores aligned to recordings by dynamic time warping. The labels are verified by trained musicians; we estimate a labeling error rate of 4%. We offer the MusicNet labels to the machine learning and music communities as a resource for training models and a common benchmark for comparing results.  URL: https://homes.cs.washington.edu/~thickstn/musicnet.html                                                                                                                                                                 | [Click here](https://academictorrents.com/details/d2b2ae5e3ec4fd475d6e4c517d4c8752a7aa8455)                                                | Music |                         |
|         MetaMIDI Dataset        |                                                                                             We introduce the MetaMIDI Dataset (MMD), a large scale collection of 436,631 MIDI files and metadata. In addition to the MIDI files, we provide artist, title and genre metadata that was collected during the scraping process when available. MIDIs in (MMD) were matched against a collection of 32,000,000 30-second audio clips retrieved from Spotify, resulting in over 10,796,557 audio-MIDI matches. In addition, we linked 600,142 Spotify tracks with 1,094,901 MusicBrainz recordings to produce a set of 168,032 MIDI files that are matched to MusicBrainz database. These links augment many files in the dataset with the extensive metadata available via the Spotify API and the MusicBrainz database. We anticipate that this collection of data will be of great use to MIR researchers addressing a variety of research topics.                                                                                             | [Click here](https://github.com/jeffreyjohnens/MetaMIDIDataset)                                                                            | Music |                         |
|            MUSDB18-HQ           |                                                                                                                                                                                                                                                                                                                                                                                                                         MUSDB18 consists of a total of 150 full-track songs of different styles and includes both the stereo mixtures and the original sources, divided between a training subset and a test subset.                                                                                                                                                                                                                                                                                                                                                                                                                         | [Click here](https://zenodo.org/record/3338373#.YaEFfbqOFaQ)                                                                               | Audio |                         |
| Cambridge-mt multitrack dataset |                                                                                                                                                                                                                                                                                                                                                                                                  Here’s a list of multitrack projects which can be freely downloaded for mixing practice purposes. All these projects are presented as ZIP archives containing uncompressed WAV files (24-bit or 16-bit resolution and 44.1kHz sample rate).                                                                                                                                                                                                                                                                                                                                                                                                 | [Click here](https://multitracksearch.cambridge-mt.com/ms-mtk-search.htm)                                                                  | Audio |                         |
|              Slakh              |                                                                                                                                                                                                                                                                                                                                                                                                                                       The Synthesized Lakh (Slakh) Dataset contains 2100 automatically mixed tracks and accompanying MIDI files synthesized using a professional-grade sampling engine.                                                                                                                                                                                                                                                                                                                                                                                                                                      | [Click here](http://www.slakh.com/)                                                                                                        | Audio |                         |
|             Tunebot             |                                                                                                                                                                                                                                                                                      The Tunebot project is an online Query By Humming system. Users sing a song to Tunebot and it returns a ranked list of song candidates available on Apple’s iTunes website. The database that Tunebot compares to sung queries is crowdsourced from users as well. Users contribute new songs to Tunebot by singing them on the Tunebot website. The more songs people contribute, the better Tunebot works. Tunebot is no longer online but the dataset lives on.                                                                                                                                                                                                                                                                                      | [Click here](https://docs.google.com/forms/d/e/1FAIpQLSeufCM32pOk8mtUTb1lohKeihHQ-42HrsEUQPDIrUuwkczBUQ/viewform) <br>(Restricted access)  | Audio |Dataset For Music Analysis - Academic Torrents   |